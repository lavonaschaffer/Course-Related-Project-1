{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/opt/conda/lib/python3.11/site-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 2.0.0 (you have 1.4.24). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import albumentations as albu  \n",
    "import numpy as np  \n",
    "import pytorch_lightning as pl  \n",
    "import segmentation_models_pytorch as smp  \n",
    "import sklearn\n",
    "import tifffile\n",
    "import torch  \n",
    "\n",
    "from pytorch_lightning import Trainer, seed_everything\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from timm.optim import create_optimizer_v2\n",
    "from timm.scheduler import create_scheduler_v2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed_everything(42)\n",
    "data_root = Path(\"./data\")\n",
    "class_names = [\"grassland_shrubland\", \"logging\", \"mining\", \"plantation\"]\n",
    "epochs = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define dataset class to load images and masks for training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mask(mask_path):\n",
    "    mask = np.load(mask_path)  # (4, H, W)\n",
    "    assert mask.shape == (4, 1024, 1024)\n",
    "    return (mask.transpose(1, 2, 0).astype(np.float32)) / 255.0  # (H, W, 4), normalized\n",
    "\n",
    "\n",
    "def load_image(image_path):\n",
    "    image = tifffile.imread(image_path)  # (H, W, 12)\n",
    "    assert image.shape == (1024, 1024, 12)\n",
    "    return np.nan_to_num(image).astype(np.float32)\n",
    "\n",
    "\n",
    "def normalize_image(image):\n",
    "    # Precomputed mean and std (12 bands)\n",
    "    mean = np.array( [\n",
    "            280.827,\n",
    "            328.215,\n",
    "            553.243,\n",
    "            393.551,\n",
    "            911.256,\n",
    "            2394.626,\n",
    "            2925.688,\n",
    "            3160.688,\n",
    "            3176.124,\n",
    "            3275.213,\n",
    "            1721.096,\n",
    "            849.122,\n",
    "        ], dtype=np.float32).reshape(12, 1, 1)\n",
    "    std = np.array( [\n",
    "            284.234,\n",
    "            240.134,\n",
    "            310.143,\n",
    "            392.992,\n",
    "            405.232,\n",
    "            615.245,\n",
    "            790.267,\n",
    "            852.903,\n",
    "            824.679,\n",
    "            809.612,\n",
    "            636.423,\n",
    "            500.186,\n",
    "        ], dtype=np.float32).reshape(12, 1, 1)\n",
    "    return (image - mean) / std\n",
    "\n",
    "\n",
    "class TrainValDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data_root, sample_indices, augmentations=None):\n",
    "        self.image_paths = [data_root / \"train_images\" / f\"train_{i}.tif\" for i in sample_indices]\n",
    "        self.mask_paths = [data_root / \"train_masks\" / f\"train_{i}.npy\" for i in sample_indices]\n",
    "        self.augmentations = augmentations\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = load_image(self.image_paths[idx])\n",
    "        mask = load_mask(self.mask_paths[idx])\n",
    "        sample = {\"image\": image, \"mask\": mask}\n",
    "\n",
    "        if self.augmentations:\n",
    "            sample = self.augmentations(**sample)\n",
    "\n",
    "        sample[\"image\"] = normalize_image(sample[\"image\"].transpose(2, 0, 1))  # (12, H, W)\n",
    "        sample[\"mask\"] = sample[\"mask\"].transpose(2, 0, 1)  # (4, H, W)\n",
    "        sample[\"image_path\"] = str(self.image_paths[idx])\n",
    "        sample[\"mask_path\"] = str(self.mask_paths[idx])\n",
    "        return sample\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define U-Net model using pytorch-lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # Initialize UNet with EfficientNetV2-S encoder\n",
    "        self.model = smp.create_model(\n",
    "            arch=\"unet\",\n",
    "            encoder_name=\"tu-tf_efficientnetv2_s\",\n",
    "            encoder_weights=\"imagenet\",\n",
    "            in_channels=12,\n",
    "            classes=4,\n",
    "        )\n",
    "\n",
    "        # Define losses\n",
    "        self.dice_loss_fn = smp.losses.DiceLoss(mode=smp.losses.MULTILABEL_MODE, from_logits=True)\n",
    "        self.bce_loss_fn = smp.losses.SoftBCEWithLogitsLoss(smooth_factor=0.0)\n",
    "\n",
    "        self.training_step_outputs = []\n",
    "        self.validation_step_outputs = []\n",
    "\n",
    "    def forward(self, image):\n",
    "        return self.model(image)\n",
    "\n",
    "    def shared_step(self, batch, stage):\n",
    "        image, mask = batch[\"image\"], batch[\"mask\"]\n",
    "        logits = self(image)\n",
    "\n",
    "        # Combine Dice + BCE losses\n",
    "        loss = self.dice_loss_fn(logits, mask) + self.bce_loss_fn(logits, mask)\n",
    "\n",
    "        # Compute classification stats\n",
    "        prob_mask = logits.sigmoid()\n",
    "        tp, fp, fn, tn = smp.metrics.get_stats(\n",
    "            (prob_mask > 0.5).long(),\n",
    "            mask.long(),\n",
    "            mode=smp.losses.MULTILABEL_MODE,\n",
    "        )\n",
    "\n",
    "        # Detach results for aggregation\n",
    "        output = {\n",
    "            \"loss\": loss.detach().cpu(),\n",
    "            \"tp\": tp.detach().cpu(),\n",
    "            \"fp\": fp.detach().cpu(),\n",
    "            \"fn\": fn.detach().cpu(),\n",
    "            \"tn\": tn.detach().cpu(),\n",
    "        }\n",
    "\n",
    "        if stage == \"train\":\n",
    "            self.training_step_outputs.append(output)\n",
    "        else:\n",
    "            self.validation_step_outputs.append(output)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        return self.shared_step(batch, \"train\")\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        return self.shared_step(batch, \"val\")\n",
    "\n",
    "    def shared_epoch_end(self, outputs, stage):\n",
    "        def log(name, val, prog_bar=False):\n",
    "            self.log(f\"{stage}/{name}\", val.to(self.device), sync_dist=True, prog_bar=prog_bar)\n",
    "\n",
    "        # Average loss\n",
    "        avg_loss = torch.stack([x[\"loss\"] for x in outputs]).mean()\n",
    "        log(\"loss\", avg_loss, prog_bar=True)\n",
    "\n",
    "        # Concatenate stats\n",
    "        tp = torch.cat([x[\"tp\"] for x in outputs])\n",
    "        fp = torch.cat([x[\"fp\"] for x in outputs])\n",
    "        fn = torch.cat([x[\"fn\"] for x in outputs])\n",
    "        tn = torch.cat([x[\"tn\"] for x in outputs])\n",
    "\n",
    "        # Compute F1 per class\n",
    "        f1_scores = {\n",
    "            class_name: smp.metrics.f1_score(tp[:, i], fp[:, i], fn[:, i], tn[:, i], reduction=\"macro-imagewise\")\n",
    "            for i, class_name in enumerate(class_names)\n",
    "        }\n",
    "        for name, score in f1_scores.items():\n",
    "            log(f\"f1/{name}\", score)\n",
    "\n",
    "        # Mean F1 across classes\n",
    "        avg_f1 = torch.stack(list(f1_scores.values())).mean()\n",
    "        log(\"f1\", avg_f1, prog_bar=True)\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        self.shared_epoch_end(self.training_step_outputs, \"train\")\n",
    "        self.training_step_outputs.clear()\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        self.shared_epoch_end(self.validation_step_outputs, \"val\")\n",
    "        self.validation_step_outputs.clear()\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        # Set up AdamW optimizer\n",
    "        optimizer = create_optimizer_v2(\n",
    "            self.parameters(),\n",
    "            opt=\"adamw\",\n",
    "            lr=1e-4,\n",
    "            weight_decay=1e-2,\n",
    "            filter_bias_and_bn=True,\n",
    "        )\n",
    "\n",
    "        # Set up cosine LR scheduler with warmup\n",
    "        scheduler, _ = create_scheduler_v2(\n",
    "            optimizer,\n",
    "            sched=\"cosine\",\n",
    "            num_epochs=epochs,\n",
    "            min_lr=0.0,\n",
    "            warmup_lr=1e-5,\n",
    "            warmup_epochs=0,\n",
    "            warmup_prefix=False,\n",
    "            step_on_epochs=True,\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"lr_scheduler\": {\n",
    "                \"scheduler\": scheduler,\n",
    "                \"interval\": \"epoch\",\n",
    "            },\n",
    "        }\n",
    "\n",
    "    def lr_scheduler_step(self, scheduler, metric):\n",
    "        # timm scheduler requires current epoch explicitly\n",
    "        scheduler.step(epoch=self.current_epoch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare trainer of pytorch-lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "# Set output directory\n",
    "train_output_dir = data_root / \"training_result\"\n",
    "\n",
    "# Split dataset into training and validation sets\n",
    "sample_indices = list(range(176))  # train_0.tif to train_175.tif\n",
    "train_indices, val_indices = sklearn.model_selection.train_test_split(\n",
    "    sample_indices, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Define training augmentations\n",
    "augmentations = albu.Compose([\n",
    "    albu.ShiftScaleRotate(\n",
    "        p=0.5, shift_limit=0.0625, scale_limit=0.1, rotate_limit=15,\n",
    "        border_mode=0, value=0, mask_value=0, interpolation=2\n",
    "    ),\n",
    "    albu.RandomCrop(p=1, width=512, height=512),\n",
    "    albu.HorizontalFlip(p=0.5),\n",
    "    albu.VerticalFlip(p=0.5),\n",
    "    albu.Transpose(p=0.5),\n",
    "    albu.RandomRotate90(p=0.5),\n",
    "])\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    TrainValDataset(data_root, train_indices, augmentations=augmentations),\n",
    "    batch_size=16,\n",
    "    num_workers=8,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    TrainValDataset(data_root, val_indices, augmentations=None),\n",
    "    batch_size=4,\n",
    "    num_workers=8,\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "# Configure PyTorch Lightning trainer\n",
    "trainer = Trainer(\n",
    "    max_epochs=epochs,\n",
    "    callbacks=[\n",
    "        ModelCheckpoint(\n",
    "            dirpath=train_output_dir,\n",
    "            filename=\"best_f1_05\",\n",
    "            monitor=\"val/f1\",\n",
    "            mode=\"max\",\n",
    "            save_weights_only=True,\n",
    "            save_top_k=1,\n",
    "            save_last=False,\n",
    "        ),\n",
    "        LearningRateMonitor(logging_interval=\"step\"),\n",
    "    ],\n",
    "    logger=[TensorBoardLogger(train_output_dir, name=None)],\n",
    "    precision=\"16-mixed\",\n",
    "    deterministic=True,\n",
    "    benchmark=False,\n",
    "    sync_batchnorm=False,\n",
    "    check_val_every_n_epoch=5,\n",
    "    default_root_dir=os.getcwd(),\n",
    "    accelerator=\"gpu\",\n",
    "    devices=[0],\n",
    "    strategy=\"ddp_notebook\",\n",
    "    log_every_n_steps=5,\n",
    ")\n",
    "\n",
    "# Initialize model\n",
    "model = Model()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start training\n",
    "\n",
    "The trained model is saved as `data/training_result/best_f1_05.ckpt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/1\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 1 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /workspace/data/training_result exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name         | Type                  | Params | Mode \n",
      "---------------------------------------------------------------\n",
      "0 | model        | Unet                  | 22.1 M | train\n",
      "1 | dice_loss_fn | DiceLoss              | 0      | train\n",
      "2 | bce_loss_fn  | SoftBCEWithLogitsLoss | 0      | train\n",
      "---------------------------------------------------------------\n",
      "22.1 M    Trainable params\n",
      "0         Non-trainable params\n",
      "22.1 M    Total params\n",
      "88.383    Total estimated model params size (MB)\n",
      "759       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199: 100%|██████████| 9/9 [00:14<00:00,  0.63it/s, v_num=0, train/loss=0.406, train/f1=0.800, val/loss=0.694, val/f1=0.552]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199: 100%|██████████| 9/9 [00:14<00:00,  0.63it/s, v_num=0, train/loss=0.406, train/f1=0.800, val/loss=0.694, val/f1=0.552]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Detected KeyboardInterrupt, attempting graceful shutdown ...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'exit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py:46\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 46\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlauncher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlaunch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m trainer_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pytorch_lightning/strategies/launchers/multiprocessing.py:144\u001b[0m, in \u001b[0;36m_MultiProcessingLauncher.launch\u001b[0;34m(self, function, trainer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocs \u001b[38;5;241m=\u001b[39m process_context\u001b[38;5;241m.\u001b[39mprocesses\n\u001b[0;32m--> 144\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mprocess_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/multiprocessing/spawn.py:132\u001b[0m, in \u001b[0;36mProcessContext.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;66;03m# Wait for any process to fail or all of them to succeed.\u001b[39;00m\n\u001b[0;32m--> 132\u001b[0m ready \u001b[38;5;241m=\u001b[39m \u001b[43mmultiprocessing\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msentinels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    137\u001b[0m error_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/multiprocessing/connection.py:948\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 948\u001b[0m     ready \u001b[38;5;241m=\u001b[39m \u001b[43mselector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    949\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ready:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/selectors.py:415\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 415\u001b[0m     fd_event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# start training\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py:539\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m TrainerStatus\u001b[38;5;241m.\u001b[39mRUNNING\n\u001b[1;32m    538\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 539\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    540\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[1;32m    541\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py:64\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(launcher, _SubprocessScriptLauncher):\n\u001b[1;32m     63\u001b[0m         launcher\u001b[38;5;241m.\u001b[39mkill(_get_sigkill_signal())\n\u001b[0;32m---> 64\u001b[0m     \u001b[43mexit\u001b[49m(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exception:\n\u001b[1;32m     67\u001b[0m     _interrupt(trainer, exception)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'exit' is not defined"
     ]
    }
   ],
   "source": [
    "# start training\n",
    "trainer.fit(\n",
    "    model,\n",
    "    train_dataloaders=train_loader,\n",
    "    val_dataloaders=val_loader,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the evaluation metric for the validation set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_inference(model, loader, pred_output_dir):\n",
    "    pred_output_dir = Path(pred_output_dir)\n",
    "    pred_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for batch in tqdm(loader):\n",
    "        images = batch[\"image\"].cuda()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits = model(images)\n",
    "            probs = logits.sigmoid()\n",
    "\n",
    "        # Save predicted probability masks\n",
    "        for i in range(images.size(0)):\n",
    "            fname = os.path.basename(batch[\"image_path\"][i])\n",
    "            mask = probs[i].cpu().numpy()  # (4, 1024, 1024)\n",
    "\n",
    "            np.save(pred_output_dir / fname.replace(\".tif\", \".npy\"), mask.astype(np.float16))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2434323/2005703213.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(train_output_dir / \"best_f1_05.ckpt\")[\"state_dict\"])\n",
      "100%|██████████| 9/9 [00:03<00:00,  2.31it/s]\n"
     ]
    }
   ],
   "source": [
    "# Load best model checkpoint and run inference on validation set\n",
    "del model  # free memory\n",
    "\n",
    "model = Model()\n",
    "state = torch.load(train_output_dir / \"best_f1_05.ckpt\")[\"state_dict\"]\n",
    "model.load_state_dict(state)\n",
    "model = model.cuda().eval()\n",
    "\n",
    "val_pred_dir = data_root / \"val_preds\"\n",
    "run_inference(model, val_loader, val_pred_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val f1 score: 0.6814\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grassland_shrubland</th>\n",
       "      <th>logging</th>\n",
       "      <th>mining</th>\n",
       "      <th>plantation</th>\n",
       "      <th>all_classes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train_9</th>\n",
       "      <td>0.925728</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.981432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_12</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_15</th>\n",
       "      <td>0.044791</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.794052</td>\n",
       "      <td>0.709711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_16</th>\n",
       "      <td>0.702484</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.906406</td>\n",
       "      <td>0.902222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_18</th>\n",
       "      <td>0.532832</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990736</td>\n",
       "      <td>0.880892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_19</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.667145</td>\n",
       "      <td>0.666786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_24</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.903910</td>\n",
       "      <td>0.975977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_29</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.622041</td>\n",
       "      <td>0.655510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_30</th>\n",
       "      <td>0.950854</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.987713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_31</th>\n",
       "      <td>0.451620</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.112905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_41</th>\n",
       "      <td>0.439609</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.927737</td>\n",
       "      <td>0.841836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_42</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.673077</td>\n",
       "      <td>0.668269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_45</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.297419</td>\n",
       "      <td>0.324355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_55</th>\n",
       "      <td>0.831889</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.957972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_60</th>\n",
       "      <td>0.772248</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.915820</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.672017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_65</th>\n",
       "      <td>0.428344</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.717877</td>\n",
       "      <td>0.945164</td>\n",
       "      <td>0.772846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_66</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.915953</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.728988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_67</th>\n",
       "      <td>0.185713</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.774938</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.740163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_82</th>\n",
       "      <td>0.319178</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.703644</td>\n",
       "      <td>0.615509</td>\n",
       "      <td>0.659583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_90</th>\n",
       "      <td>0.067316</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500793</td>\n",
       "      <td>0.392027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_109</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.883693</td>\n",
       "      <td>0.720923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_111</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.627266</td>\n",
       "      <td>0.656817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_113</th>\n",
       "      <td>0.044644</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.803571</td>\n",
       "      <td>0.462054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_114</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.985761</td>\n",
       "      <td>0.746440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_117</th>\n",
       "      <td>0.337296</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.938451</td>\n",
       "      <td>0.818937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_118</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.905993</td>\n",
       "      <td>0.726498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_119</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.753157</td>\n",
       "      <td>0.688289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_127</th>\n",
       "      <td>0.148983</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.537246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_139</th>\n",
       "      <td>0.496079</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.657472</td>\n",
       "      <td>0.788388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_140</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.957659</td>\n",
       "      <td>0.489415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_144</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.579931</td>\n",
       "      <td>0.644983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_150</th>\n",
       "      <td>0.644336</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.828926</td>\n",
       "      <td>0.868316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_160</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_167</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_169</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_172</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>all_images</th>\n",
       "      <td>0.397887</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.889673</td>\n",
       "      <td>0.715719</td>\n",
       "      <td>0.681375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            grassland_shrubland   logging    mining  plantation  all_classes\n",
       "train_9                0.925728  1.000000  1.000000    1.000000     0.981432\n",
       "train_12               0.000000  1.000000  1.000000    0.000000     0.500000\n",
       "train_15               0.044791  1.000000  1.000000    0.794052     0.709711\n",
       "train_16               0.702484  1.000000  1.000000    0.906406     0.902222\n",
       "train_18               0.532832  1.000000  1.000000    0.990736     0.880892\n",
       "train_19               0.000000  1.000000  1.000000    0.667145     0.666786\n",
       "train_24               1.000000  1.000000  1.000000    0.903910     0.975977\n",
       "train_29               0.000000  1.000000  1.000000    0.622041     0.655510\n",
       "train_30               0.950854  1.000000  1.000000    1.000000     0.987713\n",
       "train_31               0.451620  0.000000  0.000000    0.000000     0.112905\n",
       "train_41               0.439609  1.000000  1.000000    0.927737     0.841836\n",
       "train_42               0.000000  1.000000  1.000000    0.673077     0.668269\n",
       "train_45               0.000000  1.000000  0.000000    0.297419     0.324355\n",
       "train_55               0.831889  1.000000  1.000000    1.000000     0.957972\n",
       "train_60               0.772248  1.000000  0.915820    0.000000     0.672017\n",
       "train_65               0.428344  1.000000  0.717877    0.945164     0.772846\n",
       "train_66               1.000000  0.000000  0.915953    1.000000     0.728988\n",
       "train_67               0.185713  1.000000  0.774938    1.000000     0.740163\n",
       "train_82               0.319178  1.000000  0.703644    0.615509     0.659583\n",
       "train_90               0.067316  1.000000  0.000000    0.500793     0.392027\n",
       "train_109              0.000000  1.000000  1.000000    0.883693     0.720923\n",
       "train_111              1.000000  0.000000  1.000000    0.627266     0.656817\n",
       "train_113              0.044644  0.000000  1.000000    0.803571     0.462054\n",
       "train_114              1.000000  0.000000  1.000000    0.985761     0.746440\n",
       "train_117              0.337296  1.000000  1.000000    0.938451     0.818937\n",
       "train_118              0.000000  1.000000  1.000000    0.905993     0.726498\n",
       "train_119              0.000000  1.000000  1.000000    0.753157     0.688289\n",
       "train_127              0.148983  1.000000  1.000000    0.000000     0.537246\n",
       "train_139              0.496079  1.000000  1.000000    0.657472     0.788388\n",
       "train_140              0.000000  0.000000  1.000000    0.957659     0.489415\n",
       "train_144              0.000000  1.000000  1.000000    0.579931     0.644983\n",
       "train_150              0.644336  1.000000  1.000000    0.828926     0.868316\n",
       "train_160              0.000000  0.000000  1.000000    1.000000     0.500000\n",
       "train_167              0.000000  0.000000  1.000000    0.000000     0.250000\n",
       "train_169              1.000000  0.000000  1.000000    1.000000     0.750000\n",
       "train_172              1.000000  0.000000  1.000000    1.000000     0.750000\n",
       "all_images             0.397887  0.722222  0.889673    0.715719     0.681375"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compute_f1_score(pred_mask, truth_mask):\n",
    "    # Both inputs are binary masks of shape (1024, 1024)\n",
    "    assert pred_mask.shape == (1024, 1024)\n",
    "    assert truth_mask.shape == (1024, 1024)\n",
    "\n",
    "    tp = ((pred_mask > 0) & (truth_mask > 0)).sum()\n",
    "    fp = ((pred_mask > 0) & (truth_mask == 0)).sum()\n",
    "    fn = ((pred_mask == 0) & (truth_mask > 0)).sum()\n",
    "\n",
    "    precision = tp / (tp + fp) if tp + fp > 0 else 1.0\n",
    "    recall = tp / (tp + fn) if tp + fn > 0 else 1.0\n",
    "    f1 = 2 * precision * recall / (precision + recall) if precision + recall > 0 else 0.0\n",
    "\n",
    "    return f1\n",
    "\n",
    "\n",
    "score_thresh = 0.5  # threshold for binarizing prediction\n",
    "min_area = 10000    # ignore small predicted areas\n",
    "\n",
    "val_f1_scores = {}\n",
    "\n",
    "for idx in sorted(val_indices):\n",
    "    fn = f\"train_{idx}\"\n",
    "\n",
    "    # Load predicted and ground truth masks\n",
    "    pred = np.load(val_pred_dir / f\"{fn}.npy\") > score_thresh  # (4, 1024, 1024)\n",
    "    truth = np.load(data_root / \"train_masks\" / f\"{fn}.npy\")   # (4, 1024, 1024)\n",
    "\n",
    "    val_f1_scores[fn] = {}\n",
    "    for i, class_name in enumerate(class_names):\n",
    "        pred_mask = pred[i]\n",
    "        if pred_mask.sum() < min_area:\n",
    "            pred_mask = np.zeros_like(pred_mask)  # discard small predictions\n",
    "\n",
    "        val_f1_scores[fn][class_name] = compute_f1_score(pred_mask, truth[i])\n",
    "\n",
    "# Convert to DataFrame\n",
    "val_f1_scores = pd.DataFrame(val_f1_scores).T\n",
    "val_f1_scores[\"all_classes\"] = val_f1_scores.mean(axis=1)     # mean F1 per image\n",
    "val_f1_scores.loc[\"all_images\"] = val_f1_scores.mean()        # mean F1 across all images\n",
    "\n",
    "print(f\"val F1 score: {val_f1_scores.loc['all_images', 'all_classes']:.4f}\")\n",
    "val_f1_scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict the evaluation images and generate a submission JSON file\n",
    "\n",
    "Let's predict the evaluation images as already done with the validation set, and generate a submission JSON file.\n",
    "\n",
    "The submission JSON file will be saved as `data/submission.json`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data_root):\n",
    "        self.image_paths = []\n",
    "        for i in range(118):  \n",
    "            self.image_paths.append(data_root / \"evaluation_images\" / f\"evaluation_{i}.tif\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = {\n",
    "            \"image\": load_image(self.image_paths[idx]),\n",
    "        }\n",
    "\n",
    "        sample[\"image\"] = sample[\"image\"].transpose(2, 0, 1)  # (12, H, W)\n",
    "        sample[\"image\"] = normalize_image(sample[\"image\"])\n",
    "\n",
    "        # add metadata\n",
    "        sample[\"image_path\"] = str(self.image_paths[idx])\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:09<00:00,  3.28it/s]\n"
     ]
    }
   ],
   "source": [
    "test_loader = torch.utils.data.DataLoader(\n",
    "    TestDataset(data_root),\n",
    "    batch_size=4,\n",
    "    num_workers=8,\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "test_pred_dir = data_root / \"test_preds\"\n",
    "run_inference(model, test_loader, test_pred_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`detect_polygons()` below extracts isolated areas as polygons from the predicted mask.\n",
    "\n",
    "The point is `min_area` parameter to filter out small areas. Small predicted areas are often false positives which decrease the evaluation score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_polygons(pred_dir, score_thresh, min_area):\n",
    "    pred_dir = Path(pred_dir)\n",
    "    pred_paths = list(pred_dir.glob(\"*.npy\"))\n",
    "    pred_paths = sorted(pred_paths)\n",
    "\n",
    "    polygons_all_imgs = {}\n",
    "    for pred_path in tqdm(pred_paths):\n",
    "        polygons_all_classes = {}\n",
    "\n",
    "        mask = np.load(pred_path)  # (4, 1024, 1024)\n",
    "        mask = mask > score_thresh  # binarize\n",
    "        for i, class_name in enumerate(class_names):\n",
    "            mask_for_a_class = mask[i]\n",
    "            if mask_for_a_class.sum() < min_area:\n",
    "                mask_for_a_class = np.zeros_like(mask_for_a_class)  # set all to zero if the predicted area is less than `min_area`\n",
    "\n",
    "            # extract polygons from the binarized mask\n",
    "            label = measure.label(mask_for_a_class, connectivity=2, background=0).astype(np.uint8)\n",
    "            polygons = []\n",
    "            for p, value in features.shapes(label, label):\n",
    "                p = shape(p).buffer(0.5)\n",
    "                p = p.simplify(tolerance=0.5)\n",
    "                polygons.append(p)\n",
    "            polygons_all_classes[class_name] = polygons\n",
    "        polygons_all_imgs[pred_path.name.replace(\".npy\", \".tif\")] = polygons_all_classes\n",
    "\n",
    "    return polygons_all_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118/118 [00:11<00:00,  9.91it/s]\n"
     ]
    }
   ],
   "source": [
    "test_pred_polygons = detect_polygons(test_pred_dir, score_thresh=score_thresh, min_area=min_area)\n",
    "\n",
    "submission_save_path = data_root / f\"submission.json\"\n",
    "\n",
    "images = []\n",
    "for img_id in range(118):  # evaluation_0.tif to evaluation_117.tif\n",
    "    annotations = []\n",
    "    for class_name in class_names:\n",
    "        for poly in test_pred_polygons[f\"evaluation_{img_id}.tif\"][class_name]:\n",
    "            seg: list[float] = []  # [x0, y0, x1, y1, ..., xN, yN]\n",
    "            for xy in poly.exterior.coords:\n",
    "                seg.extend(xy)\n",
    "\n",
    "            annotations.append({\"class\": class_name, \"segmentation\": seg})\n",
    "\n",
    "    images.append({\"file_name\": f\"evaluation_{img_id}.tif\", \"annotations\": annotations})\n",
    "\n",
    "with open(submission_save_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump({\"images\": images}, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
